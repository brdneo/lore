#!/usr/bin/env python3
"""
An√°lise Completa do Roadmap PROXIMOS-PASSOS.md - Lore N.A.
=========================================================

Verifica o status de implementa√ß√£o de cada etapa do roadmap definido
no documento PROXIMOS-PASSOS.md, comparando com o c√≥digo existente.

Autor: Lore N.A. Roadmap Analysis Team
Data: 2025-07-05
"""

import os
import sys
from pathlib import Path
from typing import Dict, List, Any, Optional
import json
from datetime import datetime

# Adicionar src ao path
sys.path.append('/home/brendo/lore/src')

class RoadmapAnalyzer:
    """Analisador de ader√™ncia ao roadmap dos pr√≥ximos passos"""
    
    def __init__(self, project_root: str = "/home/brendo/lore"):
        self.project_root = Path(project_root)
        self.src_dir = self.project_root / "src"
        
        # Roadmap estruturado baseado no PROXIMOS-PASSOS.md
        self.roadmap = self._load_roadmap_structure()
        
        # Resultados da an√°lise
        self.implementation_status = {}
        
    def _load_roadmap_structure(self) -> Dict[str, Any]:
        """Carrega estrutura do roadmap do PROXIMOS-PASSOS.md"""
        
        return {
            "sistema_nucleo": {
                "description": "SISTEMA N√öCLEO COMPLETO ‚úÖ",
                "items": {
                    "dna_digital": {
                        "description": "Sistema de DNA Digital Completo",
                        "requirements": [
                            "Genesis Protocol com 5 universos",
                            "25+ traits gen√©ticos comportamentais", 
                            "Heran√ßa, crossover, muta√ß√£o e fitness scoring"
                        ],
                        "files": ["agent_dna.py", "evolved_agent.py"],
                        "status": "unknown"
                    },
                    "identidades_unicas": {
                        "description": "Sistema de Identidades √önicas",
                        "requirements": [
                            "Gerador de nomes √∫nicos (1000+ combina√ß√µes)",
                            "Personalidades emergentes baseadas em DNA",
                            "T√≠tulos, origens culturais e apresenta√ß√µes"
                        ],
                        "files": ["agent_name_generator.py", "base_agent.py"],
                        "status": "unknown"
                    },
                    "rede_social_neural": {
                        "description": "Rede Social Neural",
                        "requirements": [
                            "Neural Web com conex√µes din√¢micas",
                            "Compatibilidade gen√©tica para conex√µes",
                            "Forma√ß√£o natural de comunidades",
                            "M√©tricas sociais avan√ßadas"
                        ],
                        "files": ["neural_web.py", "social_network_manager.py"],
                        "status": "unknown"
                    },
                    "motor_evolucao": {
                        "description": "Motor de Evolu√ß√£o",
                        "requirements": [
                            "Sele√ß√£o natural baseada em fitness",
                            "Reprodu√ß√£o sexual com crossover gen√©tico",
                            "Muta√ß√µes gaussianas controladas",
                            "Gerenciamento de gera√ß√µes"
                        ],
                        "files": ["population_manager.py", "agent_dna.py"],
                        "status": "unknown"
                    },
                    "modulos_avancados": {
                        "description": "M√≥dulos Avan√ßados",
                        "requirements": [
                            "API Server (FastAPI) com documenta√ß√£o autom√°tica",
                            "Dashboard visual (Streamlit) para visualiza√ß√µes",
                            "Sistema de economia emocional com tokens",
                            "Launcher unificado para todos os m√≥dulos"
                        ],
                        "files": ["api_server.py", "dashboard.py", "emotional_economy.py", "advanced_launcher.py"],
                        "status": "unknown"
                    }
                }
            },
            "fase1_consolidacao": {
                "description": "FASE 1: CONSOLIDA√á√ÉO (Pr√≥ximas 2-4 semanas)",
                "items": {
                    "otimizacao_performance": {
                        "description": "Otimiza√ß√£o de Performance",
                        "requirements": [
                            "Algoritmos mais eficientes para popula√ß√µes grandes",
                            "Cache inteligente para c√°lculos gen√©ticos",
                            "Paraleliza√ß√£o de processamento"
                        ],
                        "files": ["caching", "async", "parallel"],
                        "status": "unknown"
                    },
                    "robustez_sistema": {
                        "description": "Robustez do Sistema",
                        "requirements": [
                            "Tratamento de erros mais abrangente",
                            "Logs estruturados para debugging",
                            "Testes automatizados mais completos"
                        ],
                        "files": ["error_handling", "logging", "tests"],
                        "status": "unknown"
                    },
                    "analytics_avancadas": {
                        "description": "Analytics Avan√ßadas",
                        "requirements": [
                            "M√©tricas de comportamento emergente",
                            "An√°lise de tend√™ncias evolutivas",
                            "Predi√ß√£o de forma√ß√£o de comunidades"
                        ],
                        "files": ["analytics", "metrics", "predictions"],
                        "status": "unknown"
                    }
                }
            },
            "fase2_expansao": {
                "description": "FASE 2: EXPANS√ÉO DE FUNCIONALIDADES (1-3 meses)",
                "items": {
                    "ia_conversacional": {
                        "description": "IA Conversacional",
                        "requirements": [
                            "Integra√ß√£o com modelos de linguagem",
                            "Cada agente com personalidade conversacional √∫nica",
                            "Sistema de mem√≥ria e aprendizado"
                        ],
                        "files": ["llm_integration", "conversation", "memory"],
                        "status": "unknown"
                    },
                    "governo_democratico": {
                        "description": "Governo Digital Democr√°tico",
                        "requirements": [
                            "Sistema de vota√ß√£o entre agentes",
                            "Pol√≠ticas emergentes baseadas em consenso",
                            "Hierarquias din√¢micas de lideran√ßa"
                        ],
                        "files": ["voting_system", "democracy", "governance"],
                        "status": "unknown"
                    },
                    "persistencia_distribuida": {
                        "description": "Persist√™ncia Distribu√≠da",
                        "requirements": [
                            "Database para hist√≥rico de popula√ß√µes",
                            "Backup autom√°tico de DNA cr√≠tico",
                            "Sincroniza√ß√£o entre inst√¢ncias"
                        ],
                        "files": ["distributed_db", "backup", "sync"],
                        "status": "unknown"
                    }
                }
            },
            "fase3_inovacoes": {
                "description": "FASE 3: INOVA√á√ïES CONCEITUAIS (3-6 meses)",
                "items": {
                    "multiverse_system": {
                        "description": "Multiverse System",
                        "requirements": [
                            "Universos paralelos com leis diferentes",
                            "Migra√ß√£o inter-dimensional de agentes",
                            "Eventos c√≥smicos que afetam m√∫ltiplas realidades"
                        ],
                        "files": ["multiverse", "dimensions", "cosmic_events"],
                        "status": "unknown"
                    },
                    "evolucao_dirigida": {
                        "description": "Evolu√ß√£o Dirigida",
                        "requirements": [
                            "Machine learning para otimiza√ß√£o gen√©tica",
                            "Objetivos evolutivos configur√°veis",
                            "Experimentos cient√≠ficos automatizados"
                        ],
                        "files": ["ml_evolution", "objectives", "experiments"],
                        "status": "unknown"
                    },
                    "gamificacao_interacao": {
                        "description": "Gamifica√ß√£o e Intera√ß√£o",
                        "requirements": [
                            "Interface de \"criador de mundos\"",
                            "Competi√ß√µes entre popula√ß√µes",
                            "Visualiza√ß√£o em realidade virtual"
                        ],
                        "files": ["world_creator", "competitions", "vr"],
                        "status": "unknown"
                    }
                }
            },
            "fase4_expansao_tecnica": {
                "description": "FASE 4: EXPANS√ÉO T√âCNICA (6-12 meses)",
                "items": {
                    "plataformas_multiplas": {
                        "description": "Plataformas M√∫ltiplas",
                        "requirements": [
                            "App m√≥vel para monitoramento",
                            "API p√∫blica para desenvolvedores",
                            "Plugins para outras plataformas"
                        ],
                        "files": ["mobile_app", "public_api", "plugins"],
                        "status": "unknown"
                    },
                    "blockchain_nfts": {
                        "description": "Blockchain e NFTs",
                        "requirements": [
                            "DNA √∫nico como NFT",
                            "Hist√≥rico imut√°vel de linhagens",
                            "Marketplace de agentes raros"
                        ],
                        "files": ["blockchain", "nft", "marketplace"],
                        "status": "unknown"
                    },
                    "ia_coletiva": {
                        "description": "IA Coletiva Emergente",
                        "requirements": [
                            "Intelig√™ncia de enxame",
                            "Resolu√ß√£o coletiva de problemas",
                            "Criatividade emergente colaborativa"
                        ],
                        "files": ["swarm_intelligence", "collective_ai", "emergence"],
                        "status": "unknown"
                    }
                }
            }
        }
    
    def analyze_file_implementation(self, file_path: Path) -> Dict[str, Any]:
        """Analisa implementa√ß√£o de um arquivo espec√≠fico"""
        
        if not file_path.exists():
            return {
                "exists": False,
                "lines": 0,
                "functions": 0,
                "classes": 0,
                "complexity_score": 0
            }
        
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            lines = len(content.split('\n'))
            functions = content.count('def ')
            classes = content.count('class ')
            
            # Score de complexidade baseado em tamanho e estrutura
            complexity_score = min(100, (lines / 10) + (functions * 5) + (classes * 10))
            
            # Verificar imports e depend√™ncias avan√ßadas
            advanced_imports = [
                'asyncio', 'typing', 'dataclass', 'json', 'logging',
                'requests', 'fastapi', 'streamlit', 'sqlite3', 'threading'
            ]
            
            imports_found = sum(1 for imp in advanced_imports if imp in content)
            
            return {
                "exists": True,
                "lines": lines,
                "functions": functions,
                "classes": classes,
                "complexity_score": complexity_score,
                "advanced_imports": imports_found,
                "content_preview": content[:200] + "..." if len(content) > 200 else content
            }
            
        except Exception as e:
            return {
                "exists": True,
                "error": str(e),
                "lines": 0,
                "functions": 0,
                "classes": 0,
                "complexity_score": 0
            }
    
    def check_concept_implementation(self, concepts: List[str]) -> Dict[str, Any]:
        """Verifica implementa√ß√£o de conceitos no c√≥digo"""
        
        python_files = list(self.src_dir.glob("*.py"))
        concept_evidence = {}
        
        for concept in concepts:
            concept_evidence[concept] = {
                "files_with_concept": [],
                "total_occurrences": 0,
                "implemented": False
            }
        
        for py_file in python_files:
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read().lower()
                
                for concept in concepts:
                    concept_lower = concept.lower()
                    occurrences = content.count(concept_lower)
                    
                    if occurrences > 0:
                        concept_evidence[concept]["files_with_concept"].append({
                            "file": py_file.name,
                            "occurrences": occurrences
                        })
                        concept_evidence[concept]["total_occurrences"] += occurrences
                        concept_evidence[concept]["implemented"] = True
                        
            except Exception:
                continue
        
        return concept_evidence
    
    def analyze_requirements_implementation(self, requirements: List[str]) -> Dict[str, Any]:
        """Analisa implementa√ß√£o de requisitos espec√≠ficos"""
        
        requirement_status = {}
        
        for req in requirements:
            # Extrair palavras-chave do requisito
            keywords = self._extract_keywords(req)
            
            # Verificar implementa√ß√£o dos conceitos
            concept_evidence = self.check_concept_implementation(keywords)
            
            # Determinar status baseado na evid√™ncia
            implemented_concepts = sum(1 for evidence in concept_evidence.values() if evidence["implemented"])
            total_concepts = len(keywords)
            
            implementation_percentage = (implemented_concepts / total_concepts * 100) if total_concepts > 0 else 0
            
            requirement_status[req] = {
                "keywords": keywords,
                "implementation_percentage": implementation_percentage,
                "concept_evidence": concept_evidence,
                "status": "implemented" if implementation_percentage >= 70 else "partial" if implementation_percentage >= 30 else "missing"
            }
        
        return requirement_status
    
    def _extract_keywords(self, requirement: str) -> List[str]:
        """Extrai palavras-chave de um requisito"""
        
        # Mapear conceitos para palavras-chave
        keyword_mapping = {
            "Genesis Protocol": ["genesis", "protocol"],
            "universos": ["universe", "limbo", "odyssey", "ritual", "engine", "logs"],
            "traits gen√©ticos": ["traits", "genetic", "genes"],
            "heran√ßa": ["inheritance", "parent", "crossover"],
            "crossover": ["crossover", "reproduction"],
            "muta√ß√£o": ["mutation", "mutate"],
            "fitness": ["fitness", "score"],
            "nomes √∫nicos": ["name", "generator", "unique"],
            "personalidades": ["personality", "archetype"],
            "Neural Web": ["neural", "web", "network"],
            "conex√µes din√¢micas": ["connection", "dynamic", "link"],
            "compatibilidade gen√©tica": ["compatibility", "genetic"],
            "comunidades": ["community", "group", "cluster"],
            "sele√ß√£o natural": ["selection", "natural", "fitness"],
            "reprodu√ß√£o sexual": ["reproduction", "sexual", "mate"],
            "gera√ß√µes": ["generation", "evolve"],
            "API Server": ["api", "server", "fastapi"],
            "FastAPI": ["fastapi", "api"],
            "Dashboard": ["dashboard", "streamlit"],
            "Streamlit": ["streamlit"],
            "economia emocional": ["emotional", "economy", "token"],
            "Launcher": ["launcher", "advanced"],
            "algoritmos eficientes": ["algorithm", "efficient", "optimize"],
            "cache": ["cache", "caching"],
            "paraleliza√ß√£o": ["parallel", "async", "thread"],
            "tratamento de erros": ["error", "exception", "try"],
            "logs estruturados": ["logging", "logger", "log"],
            "testes automatizados": ["test", "unittest", "pytest"],
            "m√©tricas": ["metrics", "measure", "analytics"],
            "comportamento emergente": ["emergent", "behavior", "emergence"],
            "tend√™ncias evolutivas": ["trend", "evolution", "analysis"],
            "predi√ß√£o": ["prediction", "predict", "forecast"],
            "modelos de linguagem": ["llm", "language", "model"],
            "conversacional": ["conversation", "chat", "dialogue"],
            "mem√≥ria": ["memory", "remember", "recall"],
            "aprendizado": ["learning", "learn", "train"],
            "vota√ß√£o": ["voting", "vote", "ballot"],
            "consenso": ["consensus", "agreement"],
            "lideran√ßa": ["leadership", "leader", "hierarchy"],
            "database": ["database", "db", "storage"],
            "backup": ["backup", "save", "persist"],
            "sincroniza√ß√£o": ["sync", "synchronize"],
            "universos paralelos": ["multiverse", "parallel", "dimension"],
            "migra√ß√£o": ["migration", "migrate", "transfer"],
            "eventos c√≥smicos": ["cosmic", "event", "universal"],
            "machine learning": ["ml", "machine", "learning"],
            "objetivos evolutivos": ["objective", "goal", "target"],
            "experimentos": ["experiment", "test", "trial"],
            "criador de mundos": ["world", "creator", "builder"],
            "competi√ß√µes": ["competition", "contest", "tournament"],
            "realidade virtual": ["vr", "virtual", "reality"],
            "app m√≥vel": ["mobile", "app", "android", "ios"],
            "API p√∫blica": ["public", "api", "external"],
            "plugins": ["plugin", "extension", "addon"],
            "blockchain": ["blockchain", "chain", "crypto"],
            "NFT": ["nft", "token", "digital"],
            "marketplace": ["marketplace", "market", "trade"],
            "intelig√™ncia de enxame": ["swarm", "collective", "hive"],
            "resolu√ß√£o coletiva": ["collective", "solve", "group"],
            "criatividade emergente": ["creativity", "creative", "emergent"]
        }
        
        keywords = []
        requirement_lower = requirement.lower()
        
        for concept, concept_keywords in keyword_mapping.items():
            if concept.lower() in requirement_lower:
                keywords.extend(concept_keywords)
        
        # Adicionar palavras-chave diretas do requisito
        words = requirement_lower.split()
        for word in words:
            if len(word) > 3 and word not in ['com', 'para', 'que', 'uma', 'dos', 'das', 'entre']:
                keywords.append(word)
        
        return list(set(keywords))  # Remover duplicatas
    
    def analyze_roadmap_implementation(self) -> Dict[str, Any]:
        """An√°lise completa da implementa√ß√£o do roadmap"""
        
        print("üîç AN√ÅLISE COMPLETA DO ROADMAP PROXIMOS-PASSOS.md")
        print("=" * 70)
        
        for phase_key, phase in self.roadmap.items():
            print(f"\nüìã {phase['description']}")
            print("-" * 50)
            
            phase_results = {}
            
            for item_key, item in phase["items"].items():
                print(f"\nüîé Analisando: {item['description']}")
                
                # Verificar arquivos espec√≠ficos se existirem
                if "files" in item and item["files"][0].endswith('.py'):
                    file_analysis = {}
                    for file_name in item["files"]:
                        file_path = self.src_dir / file_name
                        analysis = self.analyze_file_implementation(file_path)
                        file_analysis[file_name] = analysis
                        
                        if analysis["exists"]:
                            print(f"   ‚úÖ {file_name}: {analysis['lines']} linhas, {analysis['functions']} fun√ß√µes")
                        else:
                            print(f"   ‚ùå {file_name}: Arquivo n√£o encontrado")
                    
                    item["file_analysis"] = file_analysis
                
                # Analisar requisitos
                requirements_analysis = self.analyze_requirements_implementation(item["requirements"])
                item["requirements_analysis"] = requirements_analysis
                
                # Calcular score geral do item
                if "file_analysis" in item:
                    # Items com arquivos espec√≠ficos
                    existing_files = sum(1 for analysis in item["file_analysis"].values() if analysis["exists"])
                    total_files = len(item["file_analysis"])
                    file_score = (existing_files / total_files * 100) if total_files > 0 else 0
                    
                    avg_complexity = sum(analysis.get("complexity_score", 0) for analysis in item["file_analysis"].values()) / total_files
                    
                    # Score baseado na exist√™ncia de arquivos e complexidade
                    item_score = (file_score * 0.6) + (min(avg_complexity, 100) * 0.4)
                else:
                    # Items conceituais - baseado na implementa√ß√£o de requisitos
                    req_scores = [req_analysis["implementation_percentage"] for req_analysis in requirements_analysis.values()]
                    item_score = sum(req_scores) / len(req_scores) if req_scores else 0
                
                # Determinar status
                if item_score >= 80:
                    item["status"] = "implemented"
                    status_icon = "‚úÖ"
                elif item_score >= 40:
                    item["status"] = "partial"
                    status_icon = "‚ö†Ô∏è"
                else:
                    item["status"] = "missing"
                    status_icon = "‚ùå"
                
                item["implementation_score"] = item_score
                print(f"   {status_icon} Score de implementa√ß√£o: {item_score:.1f}%")
                
                # Mostrar detalhes dos requisitos
                for req, req_analysis in requirements_analysis.items():
                    if req_analysis["implementation_percentage"] >= 70:
                        print(f"      ‚úÖ {req}: {req_analysis['implementation_percentage']:.0f}%")
                    elif req_analysis["implementation_percentage"] >= 30:
                        print(f"      ‚ö†Ô∏è {req}: {req_analysis['implementation_percentage']:.0f}%")
                    else:
                        print(f"      ‚ùå {req}: {req_analysis['implementation_percentage']:.0f}%")
                
                phase_results[item_key] = item
            
            # Calcular score da fase
            phase_scores = [item["implementation_score"] for item in phase_results.values()]
            phase["implementation_score"] = sum(phase_scores) / len(phase_scores) if phase_scores else 0
            
            print(f"\nüìä SCORE DA FASE: {phase['implementation_score']:.1f}%")
            
            self.implementation_status[phase_key] = phase
    
    def generate_roadmap_report(self) -> str:
        """Gera relat√≥rio completo da an√°lise do roadmap"""
        
        report = []
        report.append("# üìã RELAT√ìRIO COMPLETO - AN√ÅLISE DO ROADMAP PROXIMOS-PASSOS.md")
        report.append(f"**Data:** {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        report.append("")
        
        # Calcular estat√≠sticas gerais
        total_items = 0
        implemented_items = 0
        partial_items = 0
        missing_items = 0
        
        phase_scores = []
        
        for phase_key, phase in self.implementation_status.items():
            phase_scores.append(phase["implementation_score"])
            
            for item_key, item in phase["items"].items():
                total_items += 1
                if item["status"] == "implemented":
                    implemented_items += 1
                elif item["status"] == "partial":
                    partial_items += 1
                else:
                    missing_items += 1
        
        overall_score = sum(phase_scores) / len(phase_scores) if phase_scores else 0
        
        # Resumo executivo
        report.append("## üéØ RESUMO EXECUTIVO")
        report.append("")
        report.append(f"**Score Geral de Implementa√ß√£o:** {overall_score:.1f}%")
        report.append("")
        report.append(f"**Estat√≠sticas do Roadmap:**")
        report.append(f"- üìä Total de itens analisados: {total_items}")
        report.append(f"- ‚úÖ Implementados: {implemented_items} ({implemented_items/total_items*100:.1f}%)")
        report.append(f"- ‚ö†Ô∏è Parcialmente implementados: {partial_items} ({partial_items/total_items*100:.1f}%)")
        report.append(f"- ‚ùå N√£o implementados: {missing_items} ({missing_items/total_items*100:.1f}%)")
        report.append("")
        
        # Status por fase
        report.append("## üìã STATUS POR FASE")
        report.append("")
        
        for phase_key, phase in self.implementation_status.items():
            score = phase["implementation_score"]
            
            if score >= 80:
                status_icon = "‚úÖ COMPLETA"
            elif score >= 60:
                status_icon = "üîÑ EM ANDAMENTO"
            elif score >= 30:
                status_icon = "‚ö†Ô∏è INICIADA"
            else:
                status_icon = "‚ùå N√ÉO INICIADA"
            
            report.append(f"### {phase['description']}")
            report.append(f"**Status:** {status_icon} ({score:.1f}%)")
            report.append("")
            
            # Listar itens da fase
            for item_key, item in phase["items"].items():
                item_score = item["implementation_score"]
                
                if item["status"] == "implemented":
                    item_icon = "‚úÖ"
                elif item["status"] == "partial":
                    item_icon = "‚ö†Ô∏è"
                else:
                    item_icon = "‚ùå"
                
                report.append(f"- {item_icon} **{item['description']}**: {item_score:.1f}%")
                
                # Mostrar requisitos cr√≠ticos
                if item["status"] != "implemented":
                    missing_reqs = []
                    for req, req_analysis in item["requirements_analysis"].items():
                        if req_analysis["implementation_percentage"] < 30:
                            missing_reqs.append(req)
                    
                    if missing_reqs:
                        report.append(f"  - üî¥ Requisitos ausentes: {len(missing_reqs)}")
                        for req in missing_reqs[:2]:  # Mostrar apenas os 2 primeiros
                            report.append(f"    - {req}")
                        if len(missing_reqs) > 2:
                            report.append(f"    - ... e mais {len(missing_reqs) - 2}")
            
            report.append("")
        
        # Pr√≥ximos passos recomendados
        report.append("## üöÄ PR√ìXIMOS PASSOS RECOMENDADOS")
        report.append("")
        
        # Identificar prioridades baseadas no roadmap
        priorities = []
        
        # Itens da Fase 1 com baixa implementa√ß√£o
        fase1 = self.implementation_status.get("fase1_consolidacao", {})
        if fase1.get("implementation_score", 0) < 80:
            priorities.append("1. üîß **Completar Fase 1 (Consolida√ß√£o)** - Otimiza√ß√£o, robustez e analytics")
        
        # Sistema n√∫cleo com lacunas
        nucleo = self.implementation_status.get("sistema_nucleo", {})
        if nucleo.get("implementation_score", 0) < 95:
            priorities.append("2. üåü **Finalizar Sistema N√∫cleo** - Completar funcionalidades b√°sicas")
        
        # Pr√≥ximas fases
        fase2 = self.implementation_status.get("fase2_expansao", {})
        if fase2.get("implementation_score", 0) < 20:
            priorities.append("3. ü§ñ **Iniciar Fase 2** - IA conversacional e governo democr√°tico")
        
        if not priorities:
            priorities.append("üéâ **Roadmap bem avan√ßado!** Considerar Fase 3 - Inova√ß√µes conceituais")
        
        for priority in priorities:
            report.append(priority)
        
        report.append("")
        
        # Conclus√£o
        report.append("## üìä CONCLUS√ÉO")
        report.append("")
        
        if overall_score >= 80:
            conclusion = "üéâ **EXCELENTE** - Roadmap muito bem implementado"
        elif overall_score >= 60:
            conclusion = "‚úÖ **BOM** - Boa ader√™ncia ao roadmap, algumas lacunas"
        elif overall_score >= 40:
            conclusion = "‚ö†Ô∏è **REGULAR** - Implementa√ß√£o parcial, precisa de foco"
        else:
            conclusion = "‚ùå **BAIXO** - Roadmap pouco implementado"
        
        report.append(f"**Avalia√ß√£o Geral:** {conclusion}")
        report.append(f"**Score:** {overall_score:.1f}% de ader√™ncia ao roadmap")
        report.append("")
        
        report.append("---")
        report.append("*Relat√≥rio gerado automaticamente pela an√°lise do roadmap Lore N.A.*")
        
        return "\n".join(report)

def main():
    """Fun√ß√£o principal"""
    print("üìã LORE N.A. - AN√ÅLISE COMPLETA DO ROADMAP")
    print("=" * 60)
    
    analyzer = RoadmapAnalyzer()
    
    # Executar an√°lise
    analyzer.analyze_roadmap_implementation()
    
    # Gerar relat√≥rio
    report = analyzer.generate_roadmap_report()
    
    # Salvar relat√≥rio
    report_file = Path("/home/brendo/lore/docs/reports/ANALISE-ROADMAP-COMPLETA.md")
    report_file.parent.mkdir(parents=True, exist_ok=True)
    
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"\nüìÑ Relat√≥rio salvo em: {report_file}")
    
    # Resumo final
    phase_scores = [phase["implementation_score"] for phase in analyzer.implementation_status.values()]
    overall_score = sum(phase_scores) / len(phase_scores) if phase_scores else 0
    
    print(f"\nüéØ RESULTADO FINAL:")
    print(f"   üìä Score geral do roadmap: {overall_score:.1f}%")
    
    for phase_key, phase in analyzer.implementation_status.items():
        score = phase["implementation_score"]
        if score >= 80:
            status = "‚úÖ COMPLETA"
        elif score >= 60:
            status = "üîÑ EM ANDAMENTO"
        elif score >= 30:
            status = "‚ö†Ô∏è INICIADA"
        else:
            status = "‚ùå N√ÉO INICIADA"
        
        print(f"   {status}: {phase['description']} ({score:.1f}%)")

if __name__ == "__main__":
    main()
